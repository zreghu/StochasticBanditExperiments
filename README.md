# StochasticBanditExperiments

In this github repo, I've implemented multiple different algorithms for the Stochastic Multi-armed Bandit Problem

Simple tests can be found in tests.py

Algorithms implemented are:
- Exploring First
- Epsilon Greedy
- Successive Elimination
- UCB1
- UCB2
- UCB Tuned
- MOSS 
- POKER (which currently doesn't work)
